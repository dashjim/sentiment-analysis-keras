{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Kaggle python3 docker image.\n",
    "For more explaintation:\n",
    "https://www.kaggle.com/junxiangji/lstm-sentiment-analysis-keras/edit \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO - What do we learn from the work\n",
    "\n",
    "This can be further tweaked by \n",
    "* ~~remove @someone in the tweets.~~\n",
    "* remove stop words.\n",
    "* make it support Chinese.\n",
    "* use word2vec during embeding.\n",
    "* change the LSTM to TextCNN ro FastText and change the parameter.\n",
    "* give emoticons more importance.\n",
    "* ~~Boosting - Observed that having an extra `neutral` category would greatly decrease `positive` acc (much worse than randomly perdition which should have 30% acc) and predition for neutral is as bad as random perdiction. We need to only train the model for `positive` and `neutral` and then ensamble them togather.~~\n",
    "    - The second model cannot tell difference between Positive and Neutral.\n",
    "* also considering that the train accuracy is high and has huge diverse with test result, we are having great overfit problem here.\n",
    "    - TODO - Need to prove this by using all data to train and some of the USED data to test, the test\n",
    "* Considering that positive has 2000 tweets at 10% acc and netural has 3000 tweets at 36% acc, we might conclude that number of cropus is top 1 factor which affects the accuracy. ** so we should consider to give more data to training when split the data to trian and test.(currently .33 suggest to .10) **\n",
    "* data set is highly imbalanced that would make the model prone to perdict everything as negitive (in every mini batch). Try to duplicate the _neutral_ by 2 times and _negtive_ by 4 times. (This may not need if we use above boosting method.)\n",
    "* ~~read more paper regarding this LSTM model.~~\n",
    "    - Using BiLSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this version we will first train model1 for Negative and the rest, then train model for Netural and Positive, then ensemble two models togather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('./data/Sentiment.csv')\n",
    "# Keeping only the neccessary columns\n",
    "data = data1[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Going on #MSNBC Live with @ThomasARoberts arou...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deer in the headlights RT @lizzwinstead: Ben C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "5  RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
       "6  RT @warriorwoman91: I liked her and was happy ...  Negative\n",
       "7  Going on #MSNBC Live with @ThomasARoberts arou...   Neutral\n",
       "8  Deer in the headlights RT @lizzwinstead: Ben C...  Negative"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "data[0:9]\n",
    "# data.dtypes\n",
    "\n",
    "# data[data.sentiment.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd84b615da0>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEfCAYAAABI9xEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd84d658908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.sentiment.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2236, 2)\n",
      "(8493, 2)\n",
      "(3142, 2)\n",
      "data shape:  (13871, 2)\n"
     ]
    }
   ],
   "source": [
    "# Common process of the data\n",
    "\n",
    "# replace the named entities\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('@.*?\\s', 'somebody ', x)))\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('\\#.*?\\s', 'something ', x)))\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "print(data[ data['sentiment'] == 'Positive'].shape)\n",
    "print(data[ data['sentiment'] == 'Negative'].shape)\n",
    "print(data[ data['sentiment'] == 'Neutral'].shape)\n",
    "\n",
    "print(\"data shape: \", data.shape)\n",
    "#print(data.tail)\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor Model 2:\\nOnly train for the neutral and positive.\\n'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>somebody how did everyone feel about the cli...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>somebody didnt catch the full something last...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>somebody no mention of tamir rice and the so...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>somebody that carly fiorina is trending  hou...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somebody something w somebody delivered the ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>somebody somebody on my first day i will res...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>going on something live with somebody around 2...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>somebody just woke up to tweet this out some...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>somebody   somebody dear somebody something ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment\n",
       "0     somebody how did everyone feel about the cli...   Neutral\n",
       "1     somebody didnt catch the full something last...  Positive\n",
       "2     somebody no mention of tamir rice and the so...   Neutral\n",
       "3     somebody that carly fiorina is trending  hou...  Positive\n",
       "4     somebody something w somebody delivered the ...  Positive\n",
       "5     somebody somebody on my first day i will res...  Positive\n",
       "7   going on something live with somebody around 2...   Neutral\n",
       "11    somebody just woke up to tweet this out some...  Positive\n",
       "13    somebody   somebody dear somebody something ...   Neutral"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model2 data size:  (5378, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFor final validation\\n'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For Model 2:\n",
    "Only train for the neutral and positive.\n",
    "'''\n",
    "data_for_model_2 = data.copy()\n",
    "\n",
    "data_for_model_2 = data_for_model_2[data_for_model_2.sentiment != \"Negative\"]\n",
    "\n",
    "data_for_model_2[0:9]\n",
    "\n",
    "print(\"model2 data size: \", data_for_model_2.shape)\n",
    "\n",
    "'''\n",
    "For final validation\n",
    "'''\n",
    "data_for_ens = data.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor model 1:\\nPreviously we have Positive, Netural, Negative. Here we mark the Neutral to Positive. \\nSo only Positive and Negative left.\\n'"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>somebody how did everyone feel about the cli...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>somebody didnt catch the full something last...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>somebody no mention of tamir rice and the so...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>somebody that carly fiorina is trending  hou...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somebody something w somebody delivered the ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>somebody somebody on my first day i will res...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>somebody i liked her and was happy when i he...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>going on something live with somebody around 2...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deer in the headlights   somebody ben carson m...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0    somebody how did everyone feel about the cli...  Positive\n",
       "1    somebody didnt catch the full something last...  Positive\n",
       "2    somebody no mention of tamir rice and the so...  Positive\n",
       "3    somebody that carly fiorina is trending  hou...  Positive\n",
       "4    somebody something w somebody delivered the ...  Positive\n",
       "5    somebody somebody on my first day i will res...  Positive\n",
       "6    somebody i liked her and was happy when i he...  Negative\n",
       "7  going on something live with somebody around 2...  Positive\n",
       "8  deer in the headlights   somebody ben carson m...  Negative"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For model 1:\n",
    "Previously we have Positive, Netural, Negative. Here we mark the Neutral to Positive. \n",
    "So only Positive and Negative left.\n",
    "'''\n",
    "\n",
    "data.loc[data.sentiment == \"Neutral\", 'sentiment'] = 'Positive'\n",
    "data[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For model 1'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[2, 50, 75, 320, 426, 23, 3, 393, 343, 93, 29, 49, 947, 11],\n",
       " [2,\n",
       "  120,\n",
       "  1746,\n",
       "  3,\n",
       "  556,\n",
       "  1,\n",
       "  29,\n",
       "  49,\n",
       "  221,\n",
       "  35,\n",
       "  189,\n",
       "  5,\n",
       "  168,\n",
       "  1280,\n",
       "  12,\n",
       "  1428,\n",
       "  1221,\n",
       "  1]]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>somebody how did everyone feel about the cli...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>somebody didnt catch the full something last...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>somebody no mention of tamir rice and the so...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>somebody that carly fiorina is trending  hou...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somebody something w somebody delivered the ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>somebody somebody on my first day i will res...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>somebody i liked her and was happy when i he...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>going on something live with somebody around 2...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deer in the headlights   somebody ben carson m...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0    somebody how did everyone feel about the cli...  Positive\n",
       "1    somebody didnt catch the full something last...  Positive\n",
       "2    somebody no mention of tamir rice and the so...  Positive\n",
       "3    somebody that carly fiorina is trending  hou...  Positive\n",
       "4    somebody something w somebody delivered the ...  Positive\n",
       "5    somebody somebody on my first day i will res...  Positive\n",
       "6    somebody i liked her and was happy when i he...  Negative\n",
       "7  going on something live with somebody around 2...  Positive\n",
       "8  deer in the headlights   somebody ben carson m...  Negative"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'For model 2'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[2, 50, 75, 320, 426, 23, 3, 393, 343, 93, 29, 49, 947, 11],\n",
       " [2,\n",
       "  120,\n",
       "  1746,\n",
       "  3,\n",
       "  556,\n",
       "  1,\n",
       "  29,\n",
       "  49,\n",
       "  221,\n",
       "  35,\n",
       "  189,\n",
       "  5,\n",
       "  168,\n",
       "  1280,\n",
       "  12,\n",
       "  1428,\n",
       "  1221,\n",
       "  1]]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''For model 1'''\n",
    "    \n",
    "max_fatures = 4000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "#tokenizer.word_counts\n",
    "# tokenizer.word_index # index started from 1 not 0.\n",
    "X[0:2] # type is list\n",
    "data[0:9]\n",
    "\n",
    "'''For model 2'''\n",
    "\n",
    "tokenizer2 = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer2.fit_on_texts(data_for_model_2['text'].values)\n",
    "\n",
    "X2 = tokenizer.texts_to_sequences(data_for_model_2['text'].values)\n",
    "#tokenizer.word_counts\n",
    "# tokenizer.word_index # index started from 1 not 0.\n",
    "X2[0:2] # type is list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (13871, 29)\n",
      "X2 shape (5378, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    2,   50,   75,  320,  426,   23,    3,\n",
       "         393,  343,   93,   29,   49,  947,   11],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           2,  120, 1746,    3,  556,    1,   29,   49,  221,   35,  189,\n",
       "           5,  168, 1280,   12, 1428, 1221,    1]], dtype=int32)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # type is array and we prefixed with zeros. This should be masked in model\n",
    "X = pad_sequences(X)\n",
    "X2 = pad_sequences(X2)\n",
    "print(\"X shape\", X.shape)\n",
    "print(\"X2 shape\", X2.shape)\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeding and Define Model\n",
    "For the following Embeding layer. The input is the sequence of words, and the out put will has one more dimension.\n",
    "Which is because now one word previously is represented as a number now become a vector (word embeding)\n",
    "\n",
    "Ref\n",
    "https://stackoverflow.com/questions/46155868/keras-embedding-layer\n",
    "\n",
    "https://keras.io/layers/embeddings/\n",
    "\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Model 1 '"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 29, 128)           512000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_23 (Spatia (None, 29, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, 392)               509600    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 786       \n",
      "=================================================================\n",
      "Total params: 1,022,386\n",
      "Trainable params: 1,022,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Model 2 '"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 29, 128)           512000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_24 (Spatia (None, 29, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_24 (Bidirectio (None, 392)               509600    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 786       \n",
      "=================================================================\n",
      "Total params: 1,022,386\n",
      "Trainable params: 1,022,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "''' Model 1 '''\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "# zeros are paddings and thus need mask\n",
    "model1.add(Embedding(max_fatures, embed_dim, mask_zero=\"Ture\", input_length = X.shape[1]))\n",
    "model1.add(SpatialDropout1D(0.1)) # TODO need to understand details of this dropout.\n",
    "model1.add(Bidirectional(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.2)))\n",
    "model1.add(Dense(2,activation='softmax'))\n",
    "model1.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model1.summary())\n",
    "\n",
    "''' Model 2 '''\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Embedding(max_fatures, embed_dim,mask_zero=\"Ture\", input_length = X2.shape[1]))\n",
    "model2.add(SpatialDropout1D(0.1))\n",
    "model2.add(Bidirectional(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.2)))\n",
    "model2.add(Dense(2,activation='softmax'))\n",
    "model2.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negetive, neutral, pos for origional data.\n",
    "\n",
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "Y # [Negative, Positive]\n",
    "\n",
    "Y2 = pd.get_dummies(data_for_model_2['sentiment']).values\n",
    "Y2 # [Neutral, Positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model 1'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11790, 29) (11790, 2)\n",
      "(2081, 29) (2081, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model 2'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4571, 29) (4571, 2)\n",
      "(807, 29) (807, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.15, random_state = 42)\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2,Y2, test_size = 0.15, random_state = 42)\n",
    "'''model 1'''\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n",
    "'''model 2'''\n",
    "print(X2_train.shape,Y2_train.shape)\n",
    "print(X2_test.shape,Y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 76s - loss: 0.5705 - acc: 0.6982\n",
      "Epoch 2/8\n",
      " - 61s - loss: 0.4747 - acc: 0.7716\n",
      "Epoch 3/8\n",
      " - 55s - loss: 0.4116 - acc: 0.8108\n",
      "Epoch 4/8\n",
      " - 55s - loss: 0.3593 - acc: 0.8405\n",
      "Epoch 5/8\n",
      " - 55s - loss: 0.3201 - acc: 0.8595\n",
      "Epoch 6/8\n",
      " - 55s - loss: 0.2803 - acc: 0.8835\n",
      "Epoch 7/8\n",
      " - 55s - loss: 0.2549 - acc: 0.8919\n",
      "Epoch 8/8\n",
      " - 56s - loss: 0.2283 - acc: 0.9028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8450efb70>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 29s - loss: 0.6157 - acc: 0.6697\n",
      "Epoch 2/8\n",
      " - 21s - loss: 0.4571 - acc: 0.7928\n",
      "Epoch 3/8\n",
      " - 22s - loss: 0.3532 - acc: 0.8477\n",
      "Epoch 4/8\n",
      " - 22s - loss: 0.2792 - acc: 0.8865\n",
      "Epoch 5/8\n",
      " - 21s - loss: 0.2263 - acc: 0.9112\n",
      "Epoch 6/8\n",
      " - 21s - loss: 0.2005 - acc: 0.9263\n",
      "Epoch 7/8\n",
      " - 22s - loss: 0.1818 - acc: 0.9313\n",
      "Epoch 8/8\n",
      " - 21s - loss: 0.1653 - acc: 0.9377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8450efbe0>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model1.fit(X_train, Y_train, epochs = 8, batch_size=batch_size, verbose = 2)\n",
    "model2.fit(X2_train, Y2_train, epochs = 8, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Score\n",
    "## Pure LSTM\n",
    "Epoch 10/100\n",
    " - 18s - loss: 0.4684 - acc: 0.8115\n",
    " \n",
    "## Ensemble \n",
    "** model 1 **\n",
    "\n",
    "Epoch 8/8\n",
    " - 62s - loss: 0.2663 - acc: 0.8882\n",
    " \n",
    "** model 2 **\n",
    "\n",
    " Epoch 8/8\n",
    " - 25s - loss: 0.2021 - acc: 0.9212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model1.save('ensemble1.h5')\n",
    "model2.save('ensemble2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model1 = load_model('ensemble1.h5')\n",
    "model2 = load_model('ensemble2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model 1 '"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.89\n",
      "acc: 0.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model 2 '"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score2: 1.86\n",
      "acc2: 0.51\n"
     ]
    }
   ],
   "source": [
    "'''model 1 '''\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n",
    "\n",
    "'''model 2 '''\n",
    "\n",
    "score2,acc2 = model.evaluate(X2_test, Y2_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score2: %.2f\" % (score2))\n",
    "print(\"acc2: %.2f\" % (acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score\n",
    "## Pure LSTM\n",
    "pos_acc 10.129870129870131 %\n",
    "neu_acc 36.811594202898554 %\n",
    "neg_acc 79.27232635060639 %\n",
    "## Bi LSTM\n",
    "pos_acc 10.179640718562874 %\n",
    "neu_acc 40.78549848942598 %\n",
    "neg_acc 80.08519701810437 %\n",
    "## Ensemble\n",
    "'model 1 '\n",
    "\n",
    "score: 0.89\n",
    "acc: 0.72\n",
    "\n",
    "'model 2 '\n",
    "\n",
    "score2: 1.86\n",
    "acc2: 0.51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBiLSTM can differenciate the 'good' and 'no good'.\\n\""
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 10 48 42 78]]\n",
      "[[0.5349576  0.46504244]]\n",
      "negative\n",
      "\n",
      " >> Perdict Performance\n",
      "8.4 ms ± 1.35 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# twt = ['Meetings: Because none of us is as dumb as all of us.']\n",
    "# twt = ['good']\n",
    "twt = ['I dont like him']\n",
    "# twt = ['not bad']\n",
    "\n",
    "'''\n",
    "BiLSTM can differenciate the 'good' and 'no good'.\n",
    "'''\n",
    "\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "print(twt)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "\n",
    "print(model.predict_proba(twt,batch_size=1,verbose = 2))\n",
    "\n",
    "# [Negative, Other] [Neutral, Positive]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(model2.predict(twt,batch_size=1,verbose = 2)[0]) == 0):\n",
    "    print(\"neutral\")\n",
    "else:\n",
    "    print(\"positive\")\n",
    "\n",
    "print(\"\\n >> Perdict Performance\")\n",
    "%timeit model.predict(twt,batch_size=1,verbose = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
