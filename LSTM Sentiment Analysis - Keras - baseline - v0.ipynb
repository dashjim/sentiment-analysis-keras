{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Kaggle python3 docker image.\n",
    "For more explaintation:\n",
    "https://www.kaggle.com/junxiangji/lstm-sentiment-analysis-keras/edit \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO - What do we learn from the work\n",
    "\n",
    "This can be further tweaked by \n",
    "* remove @someone in the tweets.\n",
    "* remove stop words.\n",
    "* use word2vec during embeding.\n",
    "* change the LSTM to Dense and change the parameter.\n",
    "* give emoticons more importance.\n",
    "* Boosting - Observed that having an extra `neutral` category would greatly decrease `positive` acc (much worse than randomly perdition which should have 30% acc) and predition for neutral is as bad as random perdiction. We need to only train the model for `positive` and `neutral` and then ensamble them togather. \n",
    "* also considering that the train accuracy is high and has huge diverse with test result, we are having great overfit problem here.\n",
    "* Considering that positive has 2000 tweets at 10% acc and netural has 3000 tweets at 36% acc, we might conclude that number of cropus is top 1 factor which affects the accuracy. ** so we should consider to give more data to training when split the data to trian and test.(currently .33 suggest to .10) **\n",
    "* data set is highly imbalanced that would make the model prone to perdict everything as negitive (in every mini batch). Try to duplicate the _neutral_ by 2 times and _negtive_ by 4 times. (This may not need if we use above boosting method.)\n",
    "* read more paper regarding this LSTM model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('./data/Sentiment.csv')\n",
    "# Keeping only the neccessary columns\n",
    "data = data1[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Going on #MSNBC Live with @ThomasARoberts arou...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deer in the headlights RT @lizzwinstead: Ben C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "5  RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
       "6  RT @warriorwoman91: I liked her and was happy ...  Negative\n",
       "7  Going on #MSNBC Live with @ThomasARoberts arou...   Neutral\n",
       "8  Deer in the headlights RT @lizzwinstead: Ben C...  Negative"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "data[0:9]\n",
    "# data.dtypes\n",
    "\n",
    "# data[data.sentiment.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd888887fd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEfCAYAAABI9xEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd88adba908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.sentiment.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4472\n",
      "16986\n",
      "27742\n",
      "(13871, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2541, 52, 78, 341, 456, 22, 2, 420, 365, 95, 29, 51, 1039, 1],\n",
       " [351,\n",
       "  125,\n",
       "  1954,\n",
       "  2,\n",
       "  597,\n",
       "  1,\n",
       "  29,\n",
       "  51,\n",
       "  228,\n",
       "  35,\n",
       "  198,\n",
       "  5,\n",
       "  175,\n",
       "  1417,\n",
       "  10,\n",
       "  1577,\n",
       "  1356,\n",
       "  847]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data[data.sentiment != \"Neutral\"]\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "print(data[ data['sentiment'] == 'Positive'].size)\n",
    "print(data[ data['sentiment'] == 'Negative'].size)\n",
    "\n",
    "# Why size and shape are not same?\n",
    "print(data.size)\n",
    "print(data.shape)\n",
    "#print(data.tail)\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_fatures = 4000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "#tokenizer.word_counts\n",
    "# tokenizer.word_index # index started from 1 not 0.\n",
    "X[0:2] # type is list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13871, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 2541,   52,   78,  341,  456,   22,    2,\n",
       "         420,  365,   95,   29,   51, 1039,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         351,  125, 1954,    2,  597,    1,   29,   51,  228,   35,  198,\n",
       "           5,  175, 1417,   10, 1577, 1356,  847]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # type is array and we prefixed with zeros. This should be masked in model\n",
    "X = pad_sequences(X)\n",
    "\n",
    "print(X.shape)\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JIM: can remove **stop words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following Embeding layer. The input is the sequence of words, and the out put will has one more dimension.\n",
    "Which is because now one word previously is represented as a number now become a vector (word embeding)\n",
    "\n",
    "Ref\n",
    "https://stackoverflow.com/questions/46155868/keras-embedding-layer\n",
    "\n",
    "https://keras.io/layers/embeddings/\n",
    "\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 29, 128)           512000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 29, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 392)               509600    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1179      \n",
      "=================================================================\n",
      "Total params: 1,022,779\n",
      "Trainable params: 1,022,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# TODO: consider using mask_zero=True\n",
    "\n",
    "model.add(Embedding(max_fatures, embed_dim,mask_zero=\"Ture\", input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(Bidirectional(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "\n",
    "# negetive, neutral, pos\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11096, 29) (11096, 3)\n",
      "(2775, 29) (2775, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 63s - loss: 0.8102 - acc: 0.6506\n",
      "Epoch 2/10\n",
      " - 56s - loss: 0.6593 - acc: 0.7240\n",
      "Epoch 3/10\n",
      " - 59s - loss: 0.5808 - acc: 0.7604\n",
      "Epoch 4/10\n",
      " - 61s - loss: 0.5279 - acc: 0.7807\n",
      "Epoch 5/10\n",
      " - 59s - loss: 0.4835 - acc: 0.8055\n",
      "Epoch 6/10\n",
      " - 55s - loss: 0.4404 - acc: 0.8235\n",
      "Epoch 7/10\n",
      " - 66s - loss: 0.4004 - acc: 0.8394\n",
      "Epoch 8/10\n",
      " - 69s - loss: 0.3722 - acc: 0.8503\n",
      "Epoch 9/10\n",
      " - 62s - loss: 0.3473 - acc: 0.8683\n",
      "Epoch 10/10\n",
      " - 60s - loss: 0.3274 - acc: 0.8689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd88889b2b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 42\n",
    "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score\n",
    "## Pure LSTM\n",
    "Epoch 10/100\n",
    " - 18s - loss: 0.4684 - acc: 0.8115\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.save('whole_model_10_round_biLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('whole_model_10_round_biLSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 29)\n",
      "(1500, 3)\n",
      "(1275, 29)\n",
      "(1275, 3)\n",
      "score: 1.11\n",
      "acc: 0.66\n"
     ]
    }
   ],
   "source": [
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "print(X_validate.shape)\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "print(Y_validate.shape)\n",
    "X_test = X_test[:-validation_size]\n",
    "print(X_test.shape)\n",
    "Y_test = Y_test[:-validation_size]\n",
    "print(Y_test.shape)\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_acc 10.179640718562874 %\n",
      "neu_acc 40.78549848942598 %\n",
      "neg_acc 80.08519701810437 %\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, neu_cnt, pos_correct, neu_correct, neg_correct = 0, 0, 0, 0, 0, 0\n",
    "for x in range(len(X_validate)):\n",
    "    \n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "#         print(\"Y_validate[x] - \", Y_validate[x], \", argmax - \", np.argmax(Y_validate[x]) )\n",
    "        if np.argmax(Y_validate[x]) == 0: # argmax reture the _index_: 0 - neg, 1 - neu, 2 - positive \n",
    "            neg_correct += 1\n",
    "        elif np.argmax(Y_validate[x]) == 1:\n",
    "            neu_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    if np.argmax(Y_validate[x]) == 1:\n",
    "        neu_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neu_acc\", neu_correct/neu_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score\n",
    "## Pure LSTM\n",
    "pos_acc 10.129870129870131 %\n",
    "neu_acc 36.811594202898554 %\n",
    "neg_acc 79.27232635060639 %\n",
    "## Bi LSTM\n",
    "pos_acc 10.179640718562874 %\n",
    "neu_acc 40.78549848942598 %\n",
    "neg_acc 80.08519701810437 %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0 146]]\n",
      "[[0.01488806 0.04913476 0.93597716]]\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# twt = ['Meetings: Because none of us is as dumb as all of us.']\n",
    "twt = ['good']\n",
    "# twt = ['no good']\n",
    "\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "print(twt)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "\n",
    "print(model.predict_proba(twt,batch_size=1,verbose = 2))\n",
    "\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"neutral\")\n",
    "elif (np.argmax(sentiment) == 2):\n",
    "    print(\"positive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
