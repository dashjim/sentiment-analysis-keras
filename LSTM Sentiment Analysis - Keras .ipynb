{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Kaggle python3 docker image.\n",
    "For more explaintation:\n",
    "https://www.kaggle.com/junxiangji/lstm-sentiment-analysis-keras/edit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('./data/Sentiment.csv')\n",
    "# Keeping only the neccessary columns\n",
    "data = data1[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Going on #MSNBC Live with @ThomasARoberts arou...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deer in the headlights RT @lizzwinstead: Ben C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
       "5  RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
       "6  RT @warriorwoman91: I liked her and was happy ...  Negative\n",
       "7  Going on #MSNBC Live with @ThomasARoberts arou...   Neutral\n",
       "8  Deer in the headlights RT @lizzwinstead: Ben C...  Negative"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "data[0:9]\n",
    "# data.dtypes\n",
    "\n",
    "# data[data.sentiment.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4610e7af28>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEfCAYAAABI9xEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f46103bcfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.sentiment.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4472\n",
      "16986\n",
      "27742\n",
      "(13871, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gopdebate': 1,\n",
       " 'the': 2,\n",
       " 'gopdebates': 3,\n",
       " 'to': 4,\n",
       " 'of': 5,\n",
       " 'is': 6,\n",
       " 'a': 7,\n",
       " 'and': 8,\n",
       " 'i': 9,\n",
       " 'in': 10,\n",
       " 'rwsurfergirl': 11,\n",
       " 'you': 12,\n",
       " 'for': 13,\n",
       " 'it': 14,\n",
       " 'trump': 15,\n",
       " 'on': 16,\n",
       " 'that': 17,\n",
       " 'fox': 18,\n",
       " 'this': 19,\n",
       " 'not': 20,\n",
       " 'was': 21,\n",
       " 'about': 22,\n",
       " 'realdonaldtrump': 23,\n",
       " 'debate': 24,\n",
       " 'amp': 25,\n",
       " 'from': 26,\n",
       " 'at': 27,\n",
       " 'news': 28,\n",
       " 'last': 29,\n",
       " 'we': 30,\n",
       " 'have': 31,\n",
       " 'be': 32,\n",
       " 'candidates': 33,\n",
       " 'me': 34,\n",
       " 'are': 35,\n",
       " 'but': 36,\n",
       " 'he': 37,\n",
       " 'just': 38,\n",
       " 'they': 39,\n",
       " 'gop': 40,\n",
       " 'so': 41,\n",
       " 'with': 42,\n",
       " 'like': 43,\n",
       " 'what': 44,\n",
       " 'who': 45,\n",
       " 'up': 46,\n",
       " 'my': 47,\n",
       " 'all': 48,\n",
       " 'megynkelly': 49,\n",
       " 'dont': 50,\n",
       " 'night': 51,\n",
       " 'how': 52,\n",
       " 'people': 53,\n",
       " 'if': 54,\n",
       " 'as': 55,\n",
       " 'foxnews': 56,\n",
       " 'has': 57,\n",
       " 'jeb': 58,\n",
       " 'bush': 59,\n",
       " 'one': 60,\n",
       " 'no': 61,\n",
       " 'do': 62,\n",
       " 'by': 63,\n",
       " 'when': 64,\n",
       " 'out': 65,\n",
       " 'their': 66,\n",
       " 'can': 67,\n",
       " 'would': 68,\n",
       " 'think': 69,\n",
       " 'will': 70,\n",
       " 'im': 71,\n",
       " 'more': 72,\n",
       " 'or': 73,\n",
       " 'get': 74,\n",
       " 'his': 75,\n",
       " 'republican': 76,\n",
       " 'president': 77,\n",
       " 'did': 78,\n",
       " 'god': 79,\n",
       " 'chris': 80,\n",
       " 'him': 81,\n",
       " 'donald': 82,\n",
       " 'its': 83,\n",
       " 'cruz': 84,\n",
       " 'should': 85,\n",
       " 'your': 86,\n",
       " 'need': 87,\n",
       " 'ask': 88,\n",
       " 'these': 89,\n",
       " 'why': 90,\n",
       " 'rubio': 91,\n",
       " 'want': 92,\n",
       " 'questions': 93,\n",
       " 'really': 94,\n",
       " 'question': 95,\n",
       " 'after': 96,\n",
       " 'said': 97,\n",
       " 'time': 98,\n",
       " 'know': 99,\n",
       " 'were': 100,\n",
       " 'only': 101,\n",
       " 'carson': 102,\n",
       " 'an': 103,\n",
       " 'pa': 104,\n",
       " 'next': 105,\n",
       " 'watching': 106,\n",
       " 'now': 107,\n",
       " 'our': 108,\n",
       " 'them': 109,\n",
       " 'than': 110,\n",
       " 'very': 111,\n",
       " 'candidate': 112,\n",
       " 'huckabee': 113,\n",
       " 'y': 114,\n",
       " 'wallace': 115,\n",
       " 'nights': 116,\n",
       " 'most': 117,\n",
       " 'tedcruz': 118,\n",
       " 'right': 119,\n",
       " 'doesnt': 120,\n",
       " 'women': 121,\n",
       " 'tonight': 122,\n",
       " 'does': 123,\n",
       " 'other': 124,\n",
       " 'didnt': 125,\n",
       " 'anyone': 126,\n",
       " 'job': 127,\n",
       " 'see': 128,\n",
       " 'fair': 129,\n",
       " 'us': 130,\n",
       " 'megyn': 131,\n",
       " 'any': 132,\n",
       " 'trying': 133,\n",
       " 'say': 134,\n",
       " 's': 135,\n",
       " 'hear': 136,\n",
       " 'face': 137,\n",
       " 'america': 138,\n",
       " 'tcot': 139,\n",
       " 'american': 140,\n",
       " 'go': 141,\n",
       " 'cant': 142,\n",
       " 'balanced': 143,\n",
       " 'got': 144,\n",
       " 'stage': 145,\n",
       " 'good': 146,\n",
       " 'where': 147,\n",
       " 'youre': 148,\n",
       " 'there': 149,\n",
       " 'never': 150,\n",
       " 'watch': 151,\n",
       " 'take': 152,\n",
       " 'great': 153,\n",
       " 'talk': 154,\n",
       " 'suppo': 155,\n",
       " 'money': 156,\n",
       " 'carlyfiorina': 157,\n",
       " 'hillary': 158,\n",
       " 'won': 159,\n",
       " 'her': 160,\n",
       " 'via': 161,\n",
       " 'am': 162,\n",
       " 'paul': 163,\n",
       " 'set': 164,\n",
       " 'field': 165,\n",
       " 'monaeltahawy': 166,\n",
       " 'ben': 167,\n",
       " 'going': 168,\n",
       " 'had': 169,\n",
       " 'g': 170,\n",
       " 'listen': 171,\n",
       " 'else': 172,\n",
       " 'during': 173,\n",
       " 'walker': 174,\n",
       " 'best': 175,\n",
       " 'presidential': 176,\n",
       " 'kasich': 177,\n",
       " 'real': 178,\n",
       " 'men': 179,\n",
       " 'attack': 180,\n",
       " 'supermanhotmale': 181,\n",
       " '2': 182,\n",
       " 'look': 183,\n",
       " 'she': 184,\n",
       " 'being': 185,\n",
       " 'over': 186,\n",
       " 'reminds': 187,\n",
       " 'debates': 188,\n",
       " 'gets': 189,\n",
       " 'kelly': 190,\n",
       " 'doing': 191,\n",
       " 'obama': 192,\n",
       " 'make': 193,\n",
       " 'even': 194,\n",
       " 'tell': 195,\n",
       " 'ted': 196,\n",
       " 'obviously': 197,\n",
       " 'some': 198,\n",
       " 'music': 199,\n",
       " 'gopdebat': 200,\n",
       " 'thanks': 201,\n",
       " 'rid': 202,\n",
       " 'elevator': 203,\n",
       " 'because': 204,\n",
       " 'military': 205,\n",
       " 'rand': 206,\n",
       " 'talking': 207,\n",
       " 'pick': 208,\n",
       " 'influence': 209,\n",
       " 'states': 210,\n",
       " 'first': 211,\n",
       " 'speaking': 212,\n",
       " 'much': 213,\n",
       " 'says': 214,\n",
       " 'christie': 215,\n",
       " 'together': 216,\n",
       " 'well': 217,\n",
       " 'makeup': 218,\n",
       " 'vote': 219,\n",
       " 'many': 220,\n",
       " 'comes': 221,\n",
       " 'united': 222,\n",
       " 'love': 223,\n",
       " 'each': 224,\n",
       " 'disappointing': 225,\n",
       " 'break': 226,\n",
       " 'better': 227,\n",
       " 'here': 228,\n",
       " 'man': 229,\n",
       " 'id': 230,\n",
       " 'band': 231,\n",
       " 'expose': 232,\n",
       " 'conducting': 233,\n",
       " 'country': 234,\n",
       " 'http': 235,\n",
       " 'ratings': 236,\n",
       " 'hes': 237,\n",
       " 'fiorina': 238,\n",
       " 'hillaryclinton': 239,\n",
       " 'big': 240,\n",
       " 'rights': 241,\n",
       " 'win': 242,\n",
       " 'punch': 243,\n",
       " 'abo': 244,\n",
       " 'randpaul': 245,\n",
       " 'back': 246,\n",
       " 'long': 247,\n",
       " 'show': 248,\n",
       " 'winner': 249,\n",
       " 'donaldtrump': 250,\n",
       " 'someone': 251,\n",
       " 'still': 252,\n",
       " 'bring': 253,\n",
       " 'issues': 254,\n",
       " 'into': 255,\n",
       " 'off': 256,\n",
       " 'twitter': 257,\n",
       " 'immigration': 258,\n",
       " 'mean': 259,\n",
       " 'made': 260,\n",
       " '10': 261,\n",
       " 'thats': 262,\n",
       " 'oh': 263,\n",
       " 'stoping': 264,\n",
       " 'thing': 265,\n",
       " 'social': 266,\n",
       " 'truth': 267,\n",
       " 'been': 268,\n",
       " 'woman': 269,\n",
       " 'softball': 270,\n",
       " 'wont': 271,\n",
       " 'republicans': 272,\n",
       " 'picking': 273,\n",
       " 'every': 274,\n",
       " 'way': 275,\n",
       " 'kill': 276,\n",
       " 'moderators': 277,\n",
       " 'carly': 278,\n",
       " 'too': 279,\n",
       " '1': 280,\n",
       " 'new': 281,\n",
       " 'cherry': 282,\n",
       " 'political': 283,\n",
       " 'ion': 284,\n",
       " 'then': 285,\n",
       " 'finances': 286,\n",
       " 'marcorubio': 287,\n",
       " 'answer': 288,\n",
       " 'down': 289,\n",
       " 'politicans': 290,\n",
       " 'w': 291,\n",
       " 'things': 292,\n",
       " 'jebbush': 293,\n",
       " 'trumps': 294,\n",
       " 'could': 295,\n",
       " 'speak': 296,\n",
       " 'adult': 297,\n",
       " 'hands': 298,\n",
       " 'sta': 299,\n",
       " 'always': 300,\n",
       " 'sure': 301,\n",
       " 'word': 302,\n",
       " 'plan': 303,\n",
       " 'tv': 304,\n",
       " 'looking': 305,\n",
       " 'posed': 306,\n",
       " 'ever': 307,\n",
       " 'picturesshould': 308,\n",
       " 'kkkorgop': 309,\n",
       " 'white': 310,\n",
       " 'realbencarson': 311,\n",
       " 'seem': 312,\n",
       " 'lol': 313,\n",
       " 'those': 314,\n",
       " 'democrats': 315,\n",
       " 'scott': 316,\n",
       " 'ive': 317,\n",
       " '2016': 318,\n",
       " 'govchristie': 319,\n",
       " 'lrihendry': 320,\n",
       " 'let': 321,\n",
       " 'actually': 322,\n",
       " 'marco': 323,\n",
       " 'control': 324,\n",
       " 'govmikehuckabee': 325,\n",
       " 'u': 326,\n",
       " 'given': 327,\n",
       " 'black': 328,\n",
       " 'media': 329,\n",
       " 'which': 330,\n",
       " 'life': 331,\n",
       " 'same': 332,\n",
       " 'day': 333,\n",
       " 'watched': 334,\n",
       " 'gopd': 335,\n",
       " 'person': 336,\n",
       " 'raising': 337,\n",
       " 'hey': 338,\n",
       " 'blacklivesmatter': 339,\n",
       " 'guys': 340,\n",
       " 'everyone': 341,\n",
       " 'lets': 342,\n",
       " 'leader': 343,\n",
       " 'goldietaylor': 344,\n",
       " 'call': 345,\n",
       " 'dear': 346,\n",
       " 'thinks': 347,\n",
       " 'closing': 348,\n",
       " 'world': 349,\n",
       " 'fact': 350,\n",
       " 'scottwalker': 351,\n",
       " 'h': 352,\n",
       " 'nomination': 353,\n",
       " 'saying': 354,\n",
       " 'johnkasich': 355,\n",
       " 'give': 356,\n",
       " 'politics': 357,\n",
       " 'nothing': 358,\n",
       " 'clinton': 359,\n",
       " 'forward': 360,\n",
       " 'wants': 361,\n",
       " 'purpose': 362,\n",
       " 'order': 363,\n",
       " 'dr': 364,\n",
       " 'change': 365,\n",
       " 'against': 366,\n",
       " 'today': 367,\n",
       " 'run': 368,\n",
       " 'two': 369,\n",
       " 'war': 370,\n",
       " 'again': 371,\n",
       " 'asked': 372,\n",
       " 'enough': 373,\n",
       " 'hell': 374,\n",
       " 'thought': 375,\n",
       " 'seen': 376,\n",
       " 'admit': 377,\n",
       " 'legitimate': 378,\n",
       " 'nails': 379,\n",
       " 'before': 380,\n",
       " 'bad': 381,\n",
       " 'chrischristie': 382,\n",
       " 'keep': 383,\n",
       " 'true': 384,\n",
       " 'please': 385,\n",
       " 'ma': 386,\n",
       " 'needs': 387,\n",
       " 'lead': 388,\n",
       " 'ente': 389,\n",
       " 'reagan': 390,\n",
       " 'state': 391,\n",
       " 'yes': 392,\n",
       " 'guy': 393,\n",
       " 'looks': 394,\n",
       " 'ericstonestreet': 395,\n",
       " 'cam': 396,\n",
       " 'problem': 397,\n",
       " 'stop': 398,\n",
       " 'hard': 399,\n",
       " 'fight': 400,\n",
       " 'larryelder': 401,\n",
       " 'wallaces': 402,\n",
       " 'trump2016': 403,\n",
       " 'live': 404,\n",
       " 'americans': 405,\n",
       " 'another': 406,\n",
       " 'womens': 407,\n",
       " 'little': 408,\n",
       " 'care': 409,\n",
       " 'running': 410,\n",
       " 'happened': 411,\n",
       " 'biggest': 412,\n",
       " 'clear': 413,\n",
       " 'potus': 414,\n",
       " 'iran': 415,\n",
       " 'impo': 416,\n",
       " 'john': 417,\n",
       " 'audience': 418,\n",
       " 'seriously': 419,\n",
       " 'climate': 420,\n",
       " 'illegal': 421,\n",
       " 'while': 422,\n",
       " 'makes': 423,\n",
       " 'believe': 424,\n",
       " '3': 425,\n",
       " 'making': 426,\n",
       " 'years': 427,\n",
       " 'enjoyed': 428,\n",
       " 'getting': 429,\n",
       " 'foxdebate': 430,\n",
       " 'nine': 431,\n",
       " '5': 432,\n",
       " 'fun': 433,\n",
       " 'bettyfckinwhite': 434,\n",
       " 'wait': 435,\n",
       " 'race': 436,\n",
       " 'ill': 437,\n",
       " 'cnn': 438,\n",
       " 'isnt': 439,\n",
       " 'hate': 440,\n",
       " 'calling': 441,\n",
       " 'help': 442,\n",
       " 'bodies': 443,\n",
       " 'wasnt': 444,\n",
       " 'lot': 445,\n",
       " 'hair': 446,\n",
       " 'frontrunner': 447,\n",
       " 'learned': 448,\n",
       " 'away': 449,\n",
       " 'voting': 450,\n",
       " 'httpt': 451,\n",
       " 'come': 452,\n",
       " 'favorite': 453,\n",
       " 'future': 454,\n",
       " 'point': 455,\n",
       " 'feel': 456,\n",
       " 'comments': 457,\n",
       " 'frankluntz': 458,\n",
       " 'donniewahlberg': 459,\n",
       " 'politicians': 460,\n",
       " 'democraticdebates': 461,\n",
       " 'democrat': 462,\n",
       " 'theyre': 463,\n",
       " 'something': 464,\n",
       " 'conservative': 465,\n",
       " '4': 466,\n",
       " 'discussing': 467,\n",
       " 'came': 468,\n",
       " 'mike': 469,\n",
       " 'jamiaw': 470,\n",
       " 'bretbaier': 471,\n",
       " 'misogyny': 472,\n",
       " 'own': 473,\n",
       " 'put': 474,\n",
       " 'pretty': 475,\n",
       " 'work': 476,\n",
       " 'performance': 477,\n",
       " 'gay': 478,\n",
       " 'voters': 479,\n",
       " 'check': 480,\n",
       " 'doubledigit': 481,\n",
       " 'far': 482,\n",
       " 'top': 483,\n",
       " 'act': 484,\n",
       " 'thingsmike': 485,\n",
       " 'salmasekela': 486,\n",
       " 'campaign': 487,\n",
       " 'anything': 488,\n",
       " 'libe': 489,\n",
       " 'shit': 490,\n",
       " 'tax': 491,\n",
       " 'heres': 492,\n",
       " 'thank': 493,\n",
       " 'deserve': 494,\n",
       " 'boy': 495,\n",
       " 'facebook': 496,\n",
       " 'seems': 497,\n",
       " 'mention': 498,\n",
       " 'isis': 499,\n",
       " 'terrorism': 500,\n",
       " 'ant': 501,\n",
       " 'p2': 502,\n",
       " 'whos': 503,\n",
       " 'debatewithbernie': 504,\n",
       " 'damn': 505,\n",
       " 'civil': 506,\n",
       " 'planned': 507,\n",
       " 'rosie': 508,\n",
       " 'maybe': 509,\n",
       " 'must': 510,\n",
       " 'gave': 511,\n",
       " 'times': 512,\n",
       " 'also': 513,\n",
       " 'morning': 514,\n",
       " 'tonights': 515,\n",
       " 'brought': 516,\n",
       " 'commercial': 517,\n",
       " 'wow': 518,\n",
       " 'under': 519,\n",
       " 'statements': 520,\n",
       " 'single': 521,\n",
       " 'called': 522,\n",
       " 'less': 523,\n",
       " 'hope': 524,\n",
       " 'group': 525,\n",
       " 'whole': 526,\n",
       " 'answers': 527,\n",
       " 'parenthood': 528,\n",
       " 'record': 529,\n",
       " 'done': 530,\n",
       " 'conservatives': 531,\n",
       " 'winners': 532,\n",
       " 'end': 533,\n",
       " 'christian': 534,\n",
       " 'may': 535,\n",
       " 'game': 536,\n",
       " 'focus': 537,\n",
       " 'deal': 538,\n",
       " 'wins': 539,\n",
       " 'youtube': 540,\n",
       " 'issue': 541,\n",
       " 'stupid': 542,\n",
       " 'wrong': 543,\n",
       " 'thoughts': 544,\n",
       " 'loser': 545,\n",
       " 'reality': 546,\n",
       " 'httptcozy12bdukx9': 547,\n",
       " 'gov': 548,\n",
       " 'everything': 549,\n",
       " 'went': 550,\n",
       " 'sma': 551,\n",
       " 'friends': 552,\n",
       " 'nobody': 553,\n",
       " 'process': 554,\n",
       " 'primary': 555,\n",
       " 'took': 556,\n",
       " 'bunch': 557,\n",
       " 'both': 558,\n",
       " 'poor': 559,\n",
       " 'sense': 560,\n",
       " 'code': 561,\n",
       " 'twitterland': 562,\n",
       " 'httptco': 563,\n",
       " 'jesus': 564,\n",
       " 'repo': 565,\n",
       " 'lost': 566,\n",
       " 'berniesanders': 567,\n",
       " 'left': 568,\n",
       " 'agree': 569,\n",
       " 'kind': 570,\n",
       " 'green': 571,\n",
       " 'class': 572,\n",
       " 'moment': 573,\n",
       " 'vs': 574,\n",
       " 'election': 575,\n",
       " 'kids': 576,\n",
       " 'told': 577,\n",
       " 'find': 578,\n",
       " 'missed': 579,\n",
       " 'losers': 580,\n",
       " 'office': 581,\n",
       " 'having': 582,\n",
       " 'read': 583,\n",
       " 'words': 584,\n",
       " 'used': 585,\n",
       " 'pimps': 586,\n",
       " 'head': 587,\n",
       " 'police': 588,\n",
       " 'name': 589,\n",
       " 'saw': 590,\n",
       " 'gopdeb': 591,\n",
       " 'r': 592,\n",
       " 'interesting': 593,\n",
       " 'fucking': 594,\n",
       " 'security': 595,\n",
       " 'fuck': 596,\n",
       " 'full': 597,\n",
       " 'tweet': 598,\n",
       " 'prolife': 599,\n",
       " 'old': 600,\n",
       " 'bernie': 601,\n",
       " 'instead': 602,\n",
       " 'aining': 603,\n",
       " 'asking': 604,\n",
       " 'apple': 605,\n",
       " 'heard': 606,\n",
       " 'brain': 607,\n",
       " 'line': 608,\n",
       " 'loved': 609,\n",
       " 'between': 610,\n",
       " 'fat': 611,\n",
       " 'correct': 612,\n",
       " 'miss': 613,\n",
       " 'couldnt': 614,\n",
       " 'yet': 615,\n",
       " 'statement': 616,\n",
       " 'florida': 617,\n",
       " 'em': 618,\n",
       " 'pattonoswalt': 619,\n",
       " 'funny': 620,\n",
       " 'respect': 621,\n",
       " 'half': 622,\n",
       " 'straight': 623,\n",
       " 'without': 624,\n",
       " 'ing': 625,\n",
       " 'ronald': 626,\n",
       " 'ccot': 627,\n",
       " 'racism': 628,\n",
       " 'remove': 629,\n",
       " 'hold': 630,\n",
       " 'primaries': 631,\n",
       " 'moderator': 632,\n",
       " 'around': 633,\n",
       " 'jobs': 634,\n",
       " 'gonna': 635,\n",
       " '1st': 636,\n",
       " 'ed': 637,\n",
       " 'giving': 638,\n",
       " 'poll': 639,\n",
       " 'tough': 640,\n",
       " 'minutes': 641,\n",
       " 'once': 642,\n",
       " 'gun': 643,\n",
       " 'httptcoauhlnza3ww': 644,\n",
       " 'ini': 645,\n",
       " 'mozgovaya': 646,\n",
       " 'ht': 647,\n",
       " 'received': 648,\n",
       " 'theres': 649,\n",
       " 'direct': 650,\n",
       " 'tweets': 651,\n",
       " 'sentedcruz': 652,\n",
       " 'analysis': 653,\n",
       " 'laws': 654,\n",
       " 'foxnewsdebate': 655,\n",
       " 'cancel': 656,\n",
       " 'hugged': 657,\n",
       " 'himself': 658,\n",
       " 'guess': 659,\n",
       " 'government': 660,\n",
       " 'httptc': 661,\n",
       " 'wonder': 662,\n",
       " 'breaking': 663,\n",
       " 'video': 664,\n",
       " 'send': 665,\n",
       " 'play': 666,\n",
       " 'perfect': 667,\n",
       " 'stay': 668,\n",
       " 'history': 669,\n",
       " 'cruzcrew': 670,\n",
       " 'dwstweets': 671,\n",
       " 'place': 672,\n",
       " 'might': 673,\n",
       " 'points': 674,\n",
       " 'mexican': 675,\n",
       " 'matter': 676,\n",
       " 'post': 677,\n",
       " 'koch': 678,\n",
       " 'mentioned': 679,\n",
       " 'marriage': 680,\n",
       " 'ok': 681,\n",
       " 'arent': 682,\n",
       " 'become': 683,\n",
       " 'nice': 684,\n",
       " 'moments': 685,\n",
       " 'pjnet': 686,\n",
       " 'wish': 687,\n",
       " 'stand': 688,\n",
       " 'kellyfile': 689,\n",
       " 'recap': 690,\n",
       " 'killing': 691,\n",
       " 'usa': 692,\n",
       " 'compton': 693,\n",
       " 'realize': 694,\n",
       " 'goptbt': 695,\n",
       " 'cleveland': 696,\n",
       " 'thebaxterbean': 697,\n",
       " 'wondering': 698,\n",
       " 'pay': 699,\n",
       " 'hangover': 700,\n",
       " 'gopde': 701,\n",
       " 'gt': 702,\n",
       " '8': 703,\n",
       " 'coming': 704,\n",
       " 'gone': 705,\n",
       " 'until': 706,\n",
       " 'least': 707,\n",
       " 'pissed': 708,\n",
       " 'attacks': 709,\n",
       " 'ass': 710,\n",
       " 'showed': 711,\n",
       " 'disappointed': 712,\n",
       " 'talks': 713,\n",
       " 'sexuality': 714,\n",
       " 're': 715,\n",
       " 'remember': 716,\n",
       " 'politically': 717,\n",
       " 'gopdeba': 718,\n",
       " 'sanders': 719,\n",
       " 'obamacare': 720,\n",
       " 'through': 721,\n",
       " 'tight': 722,\n",
       " 'stands': 723,\n",
       " 'none': 724,\n",
       " 'cut': 725,\n",
       " 'failed': 726,\n",
       " 'bencarson': 727,\n",
       " 'earned': 728,\n",
       " 'past': 729,\n",
       " 'imwithhuck': 730,\n",
       " 'taking': 731,\n",
       " 'games': 732,\n",
       " 'dc': 733,\n",
       " 'comedy': 734,\n",
       " 'sorry': 735,\n",
       " 'hours': 736,\n",
       " 'ha': 737,\n",
       " 'policy': 738,\n",
       " 'calls': 739,\n",
       " 'response': 740,\n",
       " 'htt': 741,\n",
       " 'probably': 742,\n",
       " 'whats': 743,\n",
       " 'jonvoyage': 744,\n",
       " 'drudge': 745,\n",
       " 'alien': 746,\n",
       " 'totally': 747,\n",
       " 'liberal': 748,\n",
       " 'proud': 749,\n",
       " 'leave': 750,\n",
       " 'perry': 751,\n",
       " 'common': 752,\n",
       " 'shows': 753,\n",
       " 'congress': 754,\n",
       " 'yeah': 755,\n",
       " 'morningjoe': 756,\n",
       " 'headed': 757,\n",
       " 'anointed': 758,\n",
       " 'msnbc': 759,\n",
       " 'crazy': 760,\n",
       " 'few': 761,\n",
       " 'already': 762,\n",
       " 'uniteblue': 763,\n",
       " 'dad': 764,\n",
       " 'year': 765,\n",
       " 'wassermanschultz': 766,\n",
       " 'use': 767,\n",
       " 'absolutely': 768,\n",
       " 'wall': 769,\n",
       " 'kwrcrow': 770,\n",
       " 'playing': 771,\n",
       " 'joke': 772,\n",
       " 'air': 773,\n",
       " 'irandeal': 774,\n",
       " 'finally': 775,\n",
       " 'since': 776,\n",
       " 'polls': 777,\n",
       " 'free': 778,\n",
       " 'outta': 779,\n",
       " 'establishment': 780,\n",
       " 'second': 781,\n",
       " 'dems': 782,\n",
       " 'httpst': 783,\n",
       " 'yall': 784,\n",
       " 'church': 785,\n",
       " 'shes': 786,\n",
       " 'destroy': 787,\n",
       " 'business': 788,\n",
       " 'correctness': 789,\n",
       " 'status': 790,\n",
       " 'jon': 791,\n",
       " 'carly2016': 792,\n",
       " 'rich': 793,\n",
       " 'farrakhan': 794,\n",
       " 'bor': 795,\n",
       " 'themselves': 796,\n",
       " 'legal': 797,\n",
       " 'china': 798,\n",
       " 'idiots': 799,\n",
       " 'bimbo': 800,\n",
       " 'prostitutes': 801,\n",
       " 'thinking': 802,\n",
       " 'canttrustabush': 803,\n",
       " 'folks': 804,\n",
       " 'wakeupamerica': 805,\n",
       " '2nd': 806,\n",
       " 'gopclowncar': 807,\n",
       " 'changed': 808,\n",
       " 'tried': 809,\n",
       " 'bankruptcy': 810,\n",
       " 'httpstcolklffn2lfy': 811,\n",
       " 'definitely': 812,\n",
       " 'rather': 813,\n",
       " 'pledge': 814,\n",
       " 'ers': 815,\n",
       " 'economy': 816,\n",
       " 'knows': 817,\n",
       " 'total': 818,\n",
       " 'different': 819,\n",
       " 'russia': 820,\n",
       " 'dream': 821,\n",
       " 'https': 822,\n",
       " 'clown': 823,\n",
       " 'worst': 824,\n",
       " 'refuse': 825,\n",
       " 'drinking': 826,\n",
       " 'odonnell': 827,\n",
       " 'bill': 828,\n",
       " 'huge': 829,\n",
       " 'shut': 830,\n",
       " 'stewa': 831,\n",
       " 'either': 832,\n",
       " 'waiting': 833,\n",
       " 'high': 834,\n",
       " 'spent': 835,\n",
       " 'coverage': 836,\n",
       " 'nominee': 837,\n",
       " 'voter': 838,\n",
       " 'public': 839,\n",
       " 'topics': 840,\n",
       " 'round': 841,\n",
       " 'learn': 842,\n",
       " 'wedding': 843,\n",
       " 'mr': 844,\n",
       " 'idea': 845,\n",
       " 'facing': 846,\n",
       " 'walker16': 847,\n",
       " 'working': 848,\n",
       " 'mess': 849,\n",
       " 'early': 850,\n",
       " 'surprise': 851,\n",
       " 'rush': 852,\n",
       " 'lies': 853,\n",
       " 'ppl': 854,\n",
       " 'chance': 855,\n",
       " 'racist': 856,\n",
       " 'die': 857,\n",
       " 'reform': 858,\n",
       " 'hand': 859,\n",
       " 'wouldnt': 860,\n",
       " 'mind': 861,\n",
       " 'human': 862,\n",
       " 'sold': 863,\n",
       " 'wo': 864,\n",
       " 'personal': 865,\n",
       " 'national': 866,\n",
       " 'home': 867,\n",
       " 'boo': 868,\n",
       " 'constitution': 869,\n",
       " 'lives': 870,\n",
       " 'strong': 871,\n",
       " 'ff': 872,\n",
       " 'hilarious': 873,\n",
       " 'cruzs': 874,\n",
       " 'education': 875,\n",
       " 'choice': 876,\n",
       " 'drink': 877,\n",
       " 'puestoloco': 878,\n",
       " 'sober': 879,\n",
       " 'httptco8s67pz8a4a': 880,\n",
       " 'proved': 881,\n",
       " 'father': 882,\n",
       " 'sad': 883,\n",
       " 'listening': 884,\n",
       " 'sexism': 885,\n",
       " 'impressed': 886,\n",
       " 'elected': 887,\n",
       " 'families': 888,\n",
       " 'though': 889,\n",
       " 'except': 890,\n",
       " 'tlot': 891,\n",
       " 'budget': 892,\n",
       " 'megan': 893,\n",
       " 'quite': 894,\n",
       " 'nation': 895,\n",
       " 'sounds': 896,\n",
       " 'afraid': 897,\n",
       " '16': 898,\n",
       " 'brothers': 899,\n",
       " 'unless': 900,\n",
       " 'everybody': 901,\n",
       " 'c': 902,\n",
       " 'middle': 903,\n",
       " 'wisconsin': 904,\n",
       " 'looked': 905,\n",
       " 'policies': 906,\n",
       " 'takes': 907,\n",
       " 'shot': 908,\n",
       " 'numbers': 909,\n",
       " 'veterans': 910,\n",
       " 'untill': 911,\n",
       " 'hopefuls': 912,\n",
       " 'brotherhood': 913,\n",
       " 'marymauldin': 914,\n",
       " 'batsask': 915,\n",
       " 'glad': 916,\n",
       " 'walkers': 917,\n",
       " 'brother': 918,\n",
       " 'course': 919,\n",
       " 'washington': 920,\n",
       " 'spoke': 921,\n",
       " 'killed': 922,\n",
       " 'sound': 923,\n",
       " 'basically': 924,\n",
       " 'hu': 925,\n",
       " 'pro': 926,\n",
       " 'knew': 927,\n",
       " 'ones': 928,\n",
       " 'laugh': 929,\n",
       " 'hardball': 930,\n",
       " 'sets': 931,\n",
       " 'standwithrand': 932,\n",
       " 'beat': 933,\n",
       " 'th': 934,\n",
       " 'unfathomable': 935,\n",
       " 'postmo': 936,\n",
       " 'surreal': 937,\n",
       " 'fire': 938,\n",
       " 'reason': 939,\n",
       " 'view': 940,\n",
       " 'er': 941,\n",
       " 'replace': 942,\n",
       " 'completely': 943,\n",
       " 'wanted': 944,\n",
       " 'behind': 945,\n",
       " 'b': 946,\n",
       " 'number': 947,\n",
       " 'close': 948,\n",
       " 'stuff': 949,\n",
       " 'disgusting': 950,\n",
       " 'movement': 951,\n",
       " 'clowns': 952,\n",
       " 'shouldnt': 953,\n",
       " 'played': 954,\n",
       " 'family': 955,\n",
       " 'tedcruz2016': 956,\n",
       " 'such': 957,\n",
       " 'independent': 958,\n",
       " 'spoken': 959,\n",
       " 'three': 960,\n",
       " 'rnc': 961,\n",
       " 'liar': 962,\n",
       " 'small': 963,\n",
       " 'system': 964,\n",
       " 'hates': 965,\n",
       " 'hunger': 966,\n",
       " 'senator': 967,\n",
       " 'toot': 968,\n",
       " 'desdemona4u': 969,\n",
       " 'yu': 970,\n",
       " 'comment': 971,\n",
       " 'amymek': 972,\n",
       " 'house': 973,\n",
       " 'taxes': 974,\n",
       " 'law': 975,\n",
       " 'join': 976,\n",
       " 'almost': 977,\n",
       " 'pres': 978,\n",
       " 'super': 979,\n",
       " 'goes': 980,\n",
       " 'yesterday': 981,\n",
       " 'surprised': 982,\n",
       " 'biased': 983,\n",
       " 'honestly': 984,\n",
       " 'telling': 985,\n",
       " 'based': 986,\n",
       " 'others': 987,\n",
       " 'million': 988,\n",
       " 'makeamericagreatagain': 989,\n",
       " 'iraq': 990,\n",
       " 'according': 991,\n",
       " 'rick': 992,\n",
       " 'talked': 993,\n",
       " 'ca': 994,\n",
       " 'hit': 995,\n",
       " 'lose': 996,\n",
       " 'mentions': 997,\n",
       " 'leaders': 998,\n",
       " 'liberals': 999,\n",
       " 'election2016': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[52, 78, 341, 456, 22, 2, 420, 365, 95, 29, 51, 1039, 1],\n",
       " [351,\n",
       "  125,\n",
       "  1954,\n",
       "  2,\n",
       "  597,\n",
       "  1,\n",
       "  29,\n",
       "  51,\n",
       "  228,\n",
       "  35,\n",
       "  198,\n",
       "  5,\n",
       "  175,\n",
       "  1417,\n",
       "  10,\n",
       "  1577,\n",
       "  1356,\n",
       "  847]]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data[data.sentiment != \"Neutral\"]\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "print(data[ data['sentiment'] == 'Positive'].size)\n",
    "print(data[ data['sentiment'] == 'Negative'].size)\n",
    "\n",
    "# Why size and shape are not same?\n",
    "print(data.size)\n",
    "print(data.shape)\n",
    "#print(data.tail)\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "#tokenizer.word_counts\n",
    "tokenizer.word_index # index started from 1 not 0.\n",
    "X[0:2] # type is list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13871, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,   52,   78,  341,  456,   22,    2,  420,\n",
       "         365,   95,   29,   51, 1039,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  351,\n",
       "         125, 1954,    2,  597,    1,   29,   51,  228,   35,  198,    5,\n",
       "         175, 1417,   10, 1577, 1356,  847]], dtype=int32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # type is array and we prefixed with zeros. This should be masked in model\n",
    "X = pad_sequences(X)\n",
    "\n",
    "print(X.shape)\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JIM: can remove **stop words**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following Embeding layer. The input is the sequence of words, and the out put will has one more dimation.\n",
    "Which is because now one word previously is represented as a number now become a vector (word embeding)\n",
    "\n",
    "Ref\n",
    "https://stackoverflow.com/questions/46155868/keras-embedding-layer\n",
    "\n",
    "https://keras.io/layers/embeddings/\n",
    "\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 28, 128)           256000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_7 (Spatial (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 591       \n",
      "=================================================================\n",
      "Total params: 511,391\n",
      "Trainable params: 511,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# TODO: consider using mask_zero=True\n",
    "\n",
    "model.add(Embedding(max_fatures, embed_dim,mask_zero=\"Ture\", input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "\n",
    "# negetive, neutral, pos\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9293, 28) (9293, 3)\n",
      "(4578, 28) (4578, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 21s - loss: 0.8572 - acc: 0.6331\n",
      "Epoch 2/100\n",
      " - 19s - loss: 0.7220 - acc: 0.6928\n",
      "Epoch 3/100\n",
      " - 20s - loss: 0.6519 - acc: 0.7313\n",
      "Epoch 4/100\n",
      " - 22s - loss: 0.6128 - acc: 0.7483\n",
      "Epoch 5/100\n",
      " - 19s - loss: 0.5756 - acc: 0.7646\n",
      "Epoch 6/100\n",
      " - 20s - loss: 0.5563 - acc: 0.7726\n",
      "Epoch 7/100\n",
      " - 22s - loss: 0.5300 - acc: 0.7847\n",
      "Epoch 8/100\n",
      " - 18s - loss: 0.5052 - acc: 0.7975\n",
      "Epoch 9/100\n",
      " - 18s - loss: 0.4831 - acc: 0.8043\n",
      "Epoch 10/100\n",
      " - 18s - loss: 0.4684 - acc: 0.8115\n",
      "Epoch 11/100\n",
      " - 18s - loss: 0.4435 - acc: 0.8241\n",
      "Epoch 12/100\n",
      " - 19s - loss: 0.4264 - acc: 0.8289\n",
      "Epoch 13/100\n",
      " - 18s - loss: 0.4168 - acc: 0.8336\n",
      "Epoch 14/100\n",
      " - 18s - loss: 0.4034 - acc: 0.8431\n",
      "Epoch 15/100\n",
      " - 22s - loss: 0.3851 - acc: 0.8450\n",
      "Epoch 16/100\n",
      " - 20s - loss: 0.3772 - acc: 0.8460\n",
      "Epoch 17/100\n",
      " - 18s - loss: 0.3631 - acc: 0.8526\n",
      "Epoch 18/100\n",
      " - 21s - loss: 0.3556 - acc: 0.8583\n",
      "Epoch 19/100\n",
      " - 19s - loss: 0.3450 - acc: 0.8598\n",
      "Epoch 20/100\n",
      " - 19s - loss: 0.3273 - acc: 0.8712\n",
      "Epoch 21/100\n",
      " - 19s - loss: 0.3254 - acc: 0.8643\n",
      "Epoch 22/100\n",
      " - 19s - loss: 0.3116 - acc: 0.8729\n",
      "Epoch 23/100\n",
      " - 19s - loss: 0.3072 - acc: 0.8752\n",
      "Epoch 24/100\n",
      " - 19s - loss: 0.3009 - acc: 0.8776\n",
      "Epoch 25/100\n",
      " - 20s - loss: 0.2866 - acc: 0.8823\n",
      "Epoch 26/100\n",
      " - 19s - loss: 0.2847 - acc: 0.8837\n",
      "Epoch 27/100\n",
      " - 19s - loss: 0.2798 - acc: 0.8863\n",
      "Epoch 28/100\n",
      " - 19s - loss: 0.2715 - acc: 0.8887\n",
      "Epoch 29/100\n",
      " - 19s - loss: 0.2681 - acc: 0.8910\n",
      "Epoch 30/100\n",
      " - 24s - loss: 0.2654 - acc: 0.8912\n",
      "Epoch 31/100\n",
      " - 19s - loss: 0.2571 - acc: 0.8971\n",
      "Epoch 32/100\n",
      " - 20s - loss: 0.2496 - acc: 0.8983\n",
      "Epoch 33/100\n",
      " - 18s - loss: 0.2494 - acc: 0.8998\n",
      "Epoch 34/100\n",
      " - 18s - loss: 0.2439 - acc: 0.9002\n",
      "Epoch 35/100\n",
      " - 18s - loss: 0.2384 - acc: 0.9023\n",
      "Epoch 36/100\n",
      " - 18s - loss: 0.2388 - acc: 0.9026\n",
      "Epoch 37/100\n",
      " - 18s - loss: 0.2367 - acc: 0.9044\n",
      "Epoch 38/100\n",
      " - 19s - loss: 0.2305 - acc: 0.9048\n",
      "Epoch 39/100\n",
      " - 19s - loss: 0.2269 - acc: 0.9066\n",
      "Epoch 40/100\n",
      " - 18s - loss: 0.2236 - acc: 0.9095\n",
      "Epoch 41/100\n",
      " - 18s - loss: 0.2260 - acc: 0.9093\n",
      "Epoch 42/100\n",
      " - 19s - loss: 0.2197 - acc: 0.9082\n",
      "Epoch 43/100\n",
      " - 18s - loss: 0.2138 - acc: 0.9126\n",
      "Epoch 44/100\n",
      " - 18s - loss: 0.2181 - acc: 0.9114\n",
      "Epoch 45/100\n",
      " - 19s - loss: 0.2151 - acc: 0.9126\n",
      "Epoch 46/100\n",
      " - 18s - loss: 0.2078 - acc: 0.9147\n",
      "Epoch 47/100\n",
      " - 18s - loss: 0.2079 - acc: 0.9154\n",
      "Epoch 48/100\n",
      " - 22s - loss: 0.2053 - acc: 0.9157\n",
      "Epoch 49/100\n",
      " - 19s - loss: 0.2022 - acc: 0.9157\n",
      "Epoch 50/100\n",
      " - 19s - loss: 0.2068 - acc: 0.9161\n",
      "Epoch 51/100\n",
      " - 19s - loss: 0.1979 - acc: 0.9194\n",
      "Epoch 52/100\n",
      " - 18s - loss: 0.1978 - acc: 0.9186\n",
      "Epoch 53/100\n",
      " - 18s - loss: 0.1984 - acc: 0.9181\n",
      "Epoch 54/100\n",
      " - 19s - loss: 0.2016 - acc: 0.9179\n",
      "Epoch 55/100\n",
      " - 20s - loss: 0.1964 - acc: 0.9178\n",
      "Epoch 56/100\n",
      " - 18s - loss: 0.1936 - acc: 0.9204\n",
      "Epoch 57/100\n",
      " - 18s - loss: 0.1936 - acc: 0.9216\n",
      "Epoch 58/100\n",
      " - 20s - loss: 0.1952 - acc: 0.9212\n",
      "Epoch 59/100\n",
      " - 23s - loss: 0.1915 - acc: 0.9233\n",
      "Epoch 60/100\n",
      " - 20s - loss: 0.1946 - acc: 0.9196\n",
      "Epoch 61/100\n",
      " - 19s - loss: 0.1944 - acc: 0.9220\n",
      "Epoch 62/100\n",
      " - 20s - loss: 0.1919 - acc: 0.9205\n",
      "Epoch 63/100\n",
      " - 20s - loss: 0.1837 - acc: 0.9232\n",
      "Epoch 64/100\n",
      " - 23s - loss: 0.1899 - acc: 0.9218\n",
      "Epoch 65/100\n",
      " - 19s - loss: 0.1824 - acc: 0.9218\n",
      "Epoch 66/100\n",
      " - 20s - loss: 0.1805 - acc: 0.9266\n",
      "Epoch 67/100\n",
      " - 20s - loss: 0.1838 - acc: 0.9259\n",
      "Epoch 68/100\n",
      " - 20s - loss: 0.1794 - acc: 0.9250\n",
      "Epoch 69/100\n",
      " - 20s - loss: 0.1800 - acc: 0.9267\n",
      "Epoch 70/100\n",
      " - 21s - loss: 0.1862 - acc: 0.9225\n",
      "Epoch 71/100\n",
      " - 19s - loss: 0.1773 - acc: 0.9244\n",
      "Epoch 72/100\n",
      " - 18s - loss: 0.1763 - acc: 0.9264\n",
      "Epoch 73/100\n",
      " - 20s - loss: 0.1729 - acc: 0.9275\n",
      "Epoch 74/100\n",
      " - 20s - loss: 0.1753 - acc: 0.9271\n",
      "Epoch 75/100\n",
      " - 20s - loss: 0.1757 - acc: 0.9242\n",
      "Epoch 76/100\n",
      " - 19s - loss: 0.1746 - acc: 0.9266\n",
      "Epoch 77/100\n",
      " - 19s - loss: 0.1777 - acc: 0.9266\n",
      "Epoch 78/100\n",
      " - 22s - loss: 0.1783 - acc: 0.9266\n",
      "Epoch 79/100\n",
      " - 20s - loss: 0.1676 - acc: 0.9299\n",
      "Epoch 80/100\n",
      " - 22s - loss: 0.1720 - acc: 0.9282\n",
      "Epoch 81/100\n",
      " - 19s - loss: 0.1700 - acc: 0.9295\n",
      "Epoch 82/100\n",
      " - 18s - loss: 0.1712 - acc: 0.9267\n",
      "Epoch 83/100\n",
      " - 19s - loss: 0.1672 - acc: 0.9303\n",
      "Epoch 84/100\n",
      " - 19s - loss: 0.1755 - acc: 0.9275\n",
      "Epoch 85/100\n",
      " - 18s - loss: 0.1724 - acc: 0.9268\n",
      "Epoch 86/100\n",
      " - 18s - loss: 0.1682 - acc: 0.9279\n",
      "Epoch 87/100\n",
      " - 18s - loss: 0.1691 - acc: 0.9287\n",
      "Epoch 88/100\n",
      " - 19s - loss: 0.1681 - acc: 0.9306\n",
      "Epoch 89/100\n",
      " - 18s - loss: 0.1701 - acc: 0.9249\n",
      "Epoch 90/100\n",
      " - 18s - loss: 0.1645 - acc: 0.9295\n",
      "Epoch 91/100\n",
      " - 18s - loss: 0.1693 - acc: 0.9287\n",
      "Epoch 92/100\n",
      " - 19s - loss: 0.1692 - acc: 0.9285\n",
      "Epoch 93/100\n",
      " - 22s - loss: 0.1643 - acc: 0.9298\n",
      "Epoch 94/100\n",
      " - 22s - loss: 0.1627 - acc: 0.9309\n",
      "Epoch 95/100\n",
      " - 20s - loss: 0.1632 - acc: 0.9311\n",
      "Epoch 96/100\n",
      " - 20s - loss: 0.1633 - acc: 0.9307\n",
      "Epoch 97/100\n",
      " - 20s - loss: 0.1638 - acc: 0.9304\n",
      "Epoch 98/100\n",
      " - 21s - loss: 0.1637 - acc: 0.9292\n",
      "Epoch 99/100\n",
      " - 22s - loss: 0.1587 - acc: 0.9323\n",
      "Epoch 100/100\n",
      " - 22s - loss: 0.1619 - acc: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46103bd710>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 52\n",
    "model.fit(X_train, Y_train, epochs = 100, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.save('whole_model_100_round_with_neutral.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('whole_model_100_round_with_neutral.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 28)\n",
      "(1500, 3)\n",
      "(3078, 28)\n",
      "(3078, 3)\n",
      "score: 2.44\n",
      "acc: 0.65\n"
     ]
    }
   ],
   "source": [
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "print(X_validate.shape)\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "print(Y_validate.shape)\n",
    "X_test = X_test[:-validation_size]\n",
    "print(X_test.shape)\n",
    "Y_test = Y_test[:-validation_size]\n",
    "print(Y_test.shape)\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_acc 10.129870129870131 %\n",
      "neu_acc 36.811594202898554 %\n",
      "neg_acc 79.27232635060639 %\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, neu_cnt, pos_correct, neu_correct, neg_correct = 0, 0, 0, 0, 0, 0\n",
    "for x in range(len(X_validate)):\n",
    "    \n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "#         print(\"Y_validate[x] - \", Y_validate[x], \", argmax - \", np.argmax(Y_validate[x]) )\n",
    "        if np.argmax(Y_validate[x]) == 0: # argmax reture the _index_: 0 - neg, 1 - neu, 2 - positive \n",
    "            neg_correct += 1\n",
    "        elif np.argmax(Y_validate[x]) == 1:\n",
    "            neu_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    if np.argmax(Y_validate[x]) == 1:\n",
    "        neu_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neu_acc\", neu_correct/neu_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  204  724    5  130    6   55 1101   55   48    5  130]]\n",
      "[[9.9445081e-01 5.5492623e-03 9.0782839e-09]]\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "twt = ['Meetings: Because none of us is as dumb as all of us.']\n",
    "# twt = ['all']\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=28, dtype='int32', value=0)\n",
    "print(twt)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "\n",
    "print(model.predict_proba(twt,batch_size=1,verbose = 2))\n",
    "\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"neutral\")\n",
    "elif (np.argmax(sentiment) == 2):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "This can be further tweaked by \n",
    "* remove @someone in the tweets.\n",
    "* remove stop words.\n",
    "* use word2vec.\n",
    "* change the LSTM to Dense and change the parameter.\n",
    "* give emoticons more importance.\n",
    "* Boosting - Observed that having an extra `neutral` category would greatly decrease `positive` acc (much worse than randomly perdition which should have 30% acc) and predition for neutral is as bad random perdiction. We need to only train the model for `positive` and `neutral` and then ensamble them togather. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
